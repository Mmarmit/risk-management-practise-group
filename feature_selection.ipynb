{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a016ea92",
   "metadata": {},
   "source": [
    "# Feature Selection in XGBoost\n",
    "This document outlines the step-by-step process for performing feature selection during the development of a machine learning model using **XGBoost** in R."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a080480",
   "metadata": {},
   "source": [
    "## 1. Initial Setup and Environment Cleanup\n",
    "\n",
    "Before beginning feature selection or model building, it's good practice to start with a clean R environment. This avoids issues caused by residual objects or plots from previous sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all existing objects from the environment\n",
    "rm(list = ls())\n",
    "\n",
    "# Clear the console output\n",
    "cat('\\014')\n",
    "\n",
    "# Trigger garbage collection to free up unused memory\n",
    "gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9e450",
   "metadata": {},
   "source": [
    "## 2. Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your working directory path (update this before running)\n",
    "working_dir <- \"\"\n",
    "\n",
    "# Set the working directory\n",
    "setwd(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad4790",
   "metadata": {},
   "source": [
    "## 3. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(coreUtils)\n",
    "library(TUISG)\n",
    "library(titanng)\n",
    "library(comet)\n",
    "library(pleiadis)\n",
    "library(dia)\n",
    "library(tidyverse)\n",
    "library(reshape2)\n",
    "library(mlr)\n",
    "library(xgboost)\n",
    "library(fst)\n",
    "library(gt)\n",
    "library(plotly)\n",
    "library(data.table)\n",
    "library(dummies)\n",
    "library(caret)\n",
    "library(magrittr)\n",
    "library(dplyr)\n",
    "library(openxlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cf617a",
   "metadata": {},
   "source": [
    "## 4. Define Functions\n",
    "\n",
    "This section defines three core functions to evaluate binary classification models:\n",
    "- `eval_func`: Calculates **Gini coefficient** and **KS statistic**\n",
    "- `auc_func`: Computes the **AUC (Area Under the ROC Curve)** using `pROC`\n",
    "- `ksTable`: Produces a detailed decile-wise KS table with cumulative gains and Gini values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59347125",
   "metadata": {},
   "source": [
    "### 4.1 Gini and KS Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56174ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "eval_func <- function(actuals, pred_prob){\n",
    "  q <- quantile(x = pred_prob, probs = seq(0, 1, length.out = 11), type = 8)\n",
    "  if(length(unique(q)) < 11){\n",
    "    q <- unique(q)\n",
    "    cat(crayon::red(\"\\nNote that quantiles are not unique. Showing only unique quantiles...\\n\"))\n",
    "  }\n",
    "  df <- data.frame(prob = pred_prob, actuals)\n",
    "  ksTable <-  df %>%\n",
    "    mutate(pBucket = cut(prob, breaks = q, include.lowest = T)) %>%\n",
    "    group_by(pBucket) %>%\n",
    "    summarise(nNonEvent = sum(actuals == 0),\n",
    "              nEvent = sum(actuals == 1)) %>%\n",
    "    mutate(nTotal = nNonEvent + nEvent) %>%\n",
    "    mutate(pct.Pop = nTotal/sum(nTotal),\n",
    "           Event.rate = nEvent / nTotal * 100) %>%\n",
    "    mutate(cum.NonEvent = cumsum(nNonEvent),\n",
    "           cum.Event = cumsum(nEvent)) %>%\n",
    "    mutate(pct.cum.NonEvent = cum.NonEvent / sum(nNonEvent) ,\n",
    "           pct.cum.Event = cum.Event / sum(nEvent)) %>%\n",
    "    mutate(pct.cum.NonEvent.lag = lag(pct.cum.NonEvent),\n",
    "           pct.cum.Event.lag = lag(pct.cum.Event)) %>%\n",
    "    mutate(ks = abs(pct.cum.NonEvent - pct.cum.Event))\n",
    "  ksTable[1,c(\"pct.cum.NonEvent.lag\",\"pct.cum.Event.lag\")] = 0\n",
    "  ksTable$Event_Enevt.lag_diff = ksTable$pct.cum.Event - ksTable$pct.cum.Event.lag\n",
    "  ksTable$NonEvent_NonEvent.lag_sum = ksTable$pct.cum.NonEvent + ksTable$pct.cum.NonEvent.lag\n",
    "  ksTable$gini_0 <- ksTable$Event_Enevt.lag_diff * ksTable$NonEvent_NonEvent.lag_sum * 0.5\n",
    "  gini = (sum(ksTable$gini_0) - 0.5)*2\n",
    "  ks = max(ksTable$ks)\n",
    "  return(list(round(gini,4),round(ks,4)))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c525e",
   "metadata": {},
   "source": [
    "### 4.2 AUC Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_func <- function(df){\n",
    "  library(pROC)\n",
    "  roc_curve = roc(df$actual, df$prob, quiet = TRUE)\n",
    "  roc_auc = auc(roc_curve)\n",
    "  auc_value <- as.numeric(roc_auc)\n",
    "  return (round(auc_value,4))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe76d2",
   "metadata": {},
   "source": [
    "### 4.3 KS Table for Decile Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b53e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ksTable <- function(actuals, pred_prob, view = T){\n",
    "  q <- quantile(x = pred_prob, probs = seq(0, 1, length.out = 11), type = 8)\n",
    "  if(length(unique(q)) < 11){\n",
    "    q <- unique(q)\n",
    "    cat(crayon::red(\"\\nNote that quantiles are not unique. Showing only unique quantiles...\\n\"))\n",
    "  }\n",
    "  df <- data.frame(prob = pred_prob, actuals)\n",
    "  ksTable <-  df %>%\n",
    "    mutate(pBucket = cut(prob, breaks = q, include.lowest = T)) %>%\n",
    "    group_by(pBucket) %>%\n",
    "    summarise(nNonEvent = sum(actuals == 0),\n",
    "              nEvent = sum(actuals == 1)) %>%\n",
    "    mutate(Decile = row_number()) %>%\n",
    "    mutate(nTotal = nNonEvent + nEvent) %>%\n",
    "    mutate(pct.Pop = nTotal/sum(nTotal),\n",
    "           Event.rate = nEvent / nTotal ) %>%\n",
    "    mutate(cum.NonEvent = cumsum(nNonEvent),\n",
    "           cum.Event = cumsum(nEvent)) %>%\n",
    "    mutate(pct.cum.NonEvent = cum.NonEvent / sum(nNonEvent),\n",
    "           pct.cum.Event = cum.Event / sum(nEvent)) %>%\n",
    "    mutate(ks = round(abs(pct.cum.NonEvent - pct.cum.Event) * 100, 2)) %>%\n",
    "    mutate(pct.cum.NonEvent.lag = lag(pct.cum.NonEvent),\n",
    "           pct.cum.Event.lag = lag(pct.cum.Event)) %>%\n",
    "    mutate(Event_Enevt.lag_diff = (pct.cum.Event + pct.cum.Event.lag),\n",
    "           NonEvent_NonEvent.lag_sum = (pct.cum.NonEvent - pct.cum.NonEvent.lag))\n",
    " \n",
    "  ksTable[1,c(\"pct.cum.NonEvent.lag\",\"pct.cum.Event.lag\")] = 0\n",
    " \n",
    "  ksTable = ksTable%>%mutate(Gini = Event_Enevt.lag_diff * NonEvent_NonEvent.lag_sum * 0.5)\n",
    " \n",
    "  ksTable[1,c(\"Gini\")] = ((ksTable$pct.cum.NonEvent[1])*(ksTable$pct.cum.Event[1])*0.5)\n",
    " \n",
    "  req_cols = c(\"Decile\", \"pBucket\", \"nNonEvent\", \"nEvent\", \"nTotal\", \"pct.Pop\", \"Event.rate\", \"cum.NonEvent\", \"cum.Event\", \"pct.cum.NonEvent\", \"pct.cum.Event\", \"ks\", \"Gini\")\n",
    " \n",
    "  return(ksTable[,req_cols])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30dac44",
   "metadata": {},
   "source": [
    "## 5. Setting up File paths and Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for training, test, and out-of-time data\n",
    "train_data_path = \"\"\n",
    "test_data_path = \"\"\n",
    "oot_data_path = \"\"\n",
    "\n",
    "# Load the variable dictionary and convert column names to lowercase\n",
    "variable_dict = \"\"\n",
    "dictionary <- fread(variable_dict)\n",
    "dictionary[, Attribute := tolower(Attribute)]\n",
    "\n",
    "# Define the target variable (dependent variable for prediction)\n",
    "target = \"\"\n",
    "\n",
    "# Set up model saving directory and filenames\n",
    "model_saving_dir = \"\"\n",
    "model_name = \"\"\n",
    "model_version = \"\"\n",
    "\n",
    "# File for saving feature importance results\n",
    "Feat_imp_file = \"\"\n",
    "\n",
    "# Variable after IV (Information Value) and Feature Importance filtering\n",
    "vars_after_IV_FI = \"\"\n",
    "\n",
    "# Construct full file paths for model and output files\n",
    "model_name = paste0(model_saving_dir, model_name, \"_\", model_version, \".rds\")\n",
    "Feat_imp_file_name = paste0(model_saving_dir, Feat_imp_file, \"_\", model_version, \".csv\")\n",
    "\n",
    "# Bin object file (for storing binning results for features)\n",
    "bin_obj = paste0(model_saving_dir, \"all_vars_binning_object.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f122a05",
   "metadata": {},
   "source": [
    "## 6. Creating Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a680daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating target\n",
    "train_data = read_csv(train_data_path)%>%\n",
    "  mutate(\n",
    "    dpd_18_60_ind = case_when(\n",
    "      dpd_18_60_ind == \"04_Bad\" ~ 1,\n",
    "      dpd_18_60_ind == \"03_Good\" ~ 0,\n",
    "      TRUE ~ NA_real_\n",
    "    ))\n",
    "test_data = read_csv(test_data_path)%>%\n",
    "  mutate(\n",
    "    dpd_18_60_ind = case_when(\n",
    "      dpd_18_60_ind == \"04_Bad\" ~ 1,\n",
    "      dpd_18_60_ind == \"03_Good\" ~ 0,\n",
    "      TRUE ~ NA_real_\n",
    "    ))\n",
    "oot_data = read_csv(oot_data_path)%>%\n",
    "  mutate(\n",
    "    dpd_18_60_ind = case_when(\n",
    "      dpd_18_60_ind == \"04_Bad\" ~ 1,\n",
    "      dpd_18_60_ind == \"03_Good\" ~ 0,\n",
    "      TRUE ~ NA_real_\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc03a7",
   "metadata": {},
   "source": [
    "## 7. Removing Features with BLacklist, Zero Variance, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_df_1 = read_csv(\"/prd/momarmi/lists/Blacklist.csv\")\n",
    "black_df_2 <- black_df_1 %>%\n",
    "  filter(blacklist == 1 | blacklist == 2 |blacklist == 3 | blacklist == 4 | blacklist == 6)\n",
    " \n",
    "blacklist1 <- as.vector(black_df_2$Attribute)\n",
    "blacklist2 <- c('dpd_18_60_ind')\n",
    " \n",
    "blacklist <- union(blacklist1, blacklist2)\n",
    "all_vars <- as.vector(black_df_1$Attribute)\n",
    "vars_list <- setdiff(all_vars, blacklist)\n",
    " \n",
    "#Dropping non numeric and blacklist variables\n",
    "predictors <- train_data[,vars_list] %>%\n",
    "  select_if(is.numeric) %>%  \n",
    "  colnames %>%\n",
    "  setdiff(blacklist)\n",
    " \n",
    "#Dropping zero variance variables\n",
    "zeroVariance <- train_data[,vars_list] %>%\n",
    "  select(one_of(predictors)) %>%\n",
    "  summarise_all(var) %>%\n",
    "  select_if(function(.) . == 0) %>%\n",
    "  colnames\n",
    "model_var = setdiff(predictors, c(zeroVariance))\n",
    "length(model_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a0decb",
   "metadata": {},
   "source": [
    "## 8. Join dictionary to get description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.frame(\"Attribute\" = as.character(model_var))\n",
    "df = left_join(df,dictionary,by=c(\"Attribute\"))\n",
    "description = df$Description\n",
    "feat_rm = data.frame('Description' = as.character((description[which(grepl(\"M =\",description))])))\n",
    "feat_rm1 = data.frame('Description' = as.character((description[which(grepl(\" at month\",description))])))\n",
    "df1 = anti_join(df,feat_rm,by=c(\"Description\"))\n",
    "df2 = anti_join(df1,feat_rm1,by=c(\"Description\"))\n",
    "\n",
    "# Removing the balance variables\n",
    "balVars <- tibble(Attribute = predictors) %>%\n",
    "  left_join(dictionary) %>%\n",
    "  filter(\n",
    "    grepl(\"Total past due amount\", Description)\n",
    "    | grepl(\"at month\", Description)\n",
    "    | grepl(\"Aggregate amount past due\", Description)\n",
    "    | grepl(\"Average total open-to-buy\", Description)\n",
    "    | grepl(\"Total scheduled monthly payment\", Description)\n",
    "    | grepl(\"Limit of overdraft of\", Description)\n",
    "    | grepl(\"Total monthly obligation\", Description)\n",
    "    | grepl(\"Aggregate financial non-mortgage actual payment\", Description)\n",
    "    | grepl(\"Aggregate financial non-mortgage amount past due\", Description)\n",
    "    | grepl(\"Aggregate bankcard term at month\", Description)\n",
    "    | grepl(\"Aggregate bankcard Minimum Payment Amount\", Description)\n",
    "    | grepl(\"Aggregate unsecured loan actual payment amount\", Description)\n",
    "    | grepl(\"Aggregate  actual payment amount at month\", Description)\n",
    "    | grepl(\"Aggregate spend at month\", Description)\n",
    "    | grepl(\"Aggregate revolving spend at month\", Description)\n",
    "    | grepl(\"Aggregate retail spend at month\", Description)\n",
    "    | grepl(\"Total payment amount\", Description)\n",
    "    | grepl(\"Min total open-to-buy for\", Description)\n",
    "    | grepl(\"Aggregate spend over the\", Description)\n",
    "    | grepl(\"Peak monthly spend over the\", Description)\n",
    "    | grepl(\"Aggregate retail spend over the\", Description)\n",
    "    | grepl(\"Delinquent Ammount\", Description)\n",
    "    | grepl(\"Total open to buy of\", Description)\n",
    "    | grepl(\"Aggregate unsecured loan amount past due\", Description)\n",
    "    | grepl(\"Aggregate excess payment\", Description)\n",
    "    | grepl(\"Total past due amount of\", Description)\n",
    "    | grepl(\"Average balance of\", Description)\n",
    "    | grepl(\"Total past due amount of\", Description)\n",
    "    | grepl(\"Total balance of\", Description)\n",
    "    | grepl(\"Max total open-to-buy\", Description)\n",
    "    | grepl(\"Total credit line of\", Description)\n",
    "    | grepl(\"Aggregate balance at\", Description)\n",
    "    # | grepl(\"Average aggregate excess payment\", Description)\n",
    "    | grepl(\"Aggregate unsecured loan balance\", Description)\n",
    "    | grepl(\"Aggregate credit line at\", Description)\n",
    "    | grepl(\"Aggregate financial non-mortgage balance\", Description)\n",
    "    | grepl(\"Aggregate bankcard amount past\", Description)\n",
    "    | grepl(\"Highest balance of\", Description)\n",
    "    | grepl(\"Maximum balance owed\", Description)\n",
    "    # | grepl(\"Aaggregate excess payment\", Description)\n",
    "    | grepl(\"Aggregate credit line at\", Description)\n",
    "  ) %>%\n",
    "  select(Attribute) %>%\n",
    "  unlist %>% unname\n",
    " \n",
    "model_var <- df2$Attribute\n",
    "model_var <- setdiff(model_var, c(balVars))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1376f",
   "metadata": {},
   "source": [
    "## 9. Data converted to numeric on model variables and imputed with -99 for null variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed3705",
   "metadata": {},
   "source": [
    "### 9.1 Convert Variables to Numeric type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[,vars_list] <- data.frame(lapply(train_data[,vars_list], as.numeric))\n",
    "test_data[,vars_list] <- data.frame(lapply(test_data[,vars_list], as.numeric))\n",
    "oot_data[,vars_list] <- data.frame(lapply(oot_data[,vars_list], as.numeric))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e59ab",
   "metadata": {},
   "source": [
    "### 9.2 Impute null values with -99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64570c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute null values; can drop them if there is sufficient data\n",
    "train_data=train_data%>%mutate(across(all_of(model_var),~replace_na(.x,-99)))\n",
    "test_data=test_data%>%mutate(across(all_of(model_var),~replace_na(.x,-99)))\n",
    "oot_data=oot_data%>%mutate(across(all_of(model_var),~replace_na(.x,-99)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15276f6c",
   "metadata": {},
   "source": [
    "### 9.3 Preparing model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d908798",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model vars\n",
    "x_train <- train_data[,model_var]\n",
    "x_test <- test_data[,model_var]\n",
    "x_oot <- oot_data[,model_var]\n",
    " \n",
    "y_train <- train_data[[target]]\n",
    "y_test <- test_data[[target]]\n",
    "y_oot <- oot_data[[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577ed7a",
   "metadata": {},
   "source": [
    "## 10. Convert dataframe to XGB DMatrix object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70390d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train<-xgb.DMatrix(as.matrix(x_train),label=y_train,x_train[[\"weight\"]])\n",
    "xgb_test<-xgb.DMatrix(as.matrix(x_test),label=y_test,x_test[[\"weight\"]])\n",
    "xgb_oot<-xgb.DMatrix(as.matrix(x_oot),label=y_oot,x_train[[\"weight\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd4bb06",
   "metadata": {},
   "source": [
    "## 11. Base model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96de786",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training model with depth 1\n",
    "param <- list(max_depth = 1, eta = 0.1,nthread = -1,\n",
    "              objective = \"binary:logistic\", eval_metric = \"auc\")\n",
    "watchlist<-list(eval = xgb_test, train = xgb_train)\n",
    "xgb <- xgb.train(param,xgb_train,watchlist,nrounds=1500,verbose=1,print_every_n = 100)\n",
    "saveRDS(xgb,file =model_name)\n",
    " \n",
    "xgb <- readRDS(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9490dc",
   "metadata": {},
   "source": [
    "## 12. Base model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot loss curve\n",
    "a<-as.data.frame(xgb$evaluation_log)\n",
    "library(reshape)\n",
    "library(ggplot2)\n",
    "b<-melt(a,id.vars =\"iter\",variable_name = \"auc\")\n",
    "ggplot(b, aes(iter,value)) + geom_line(aes(colour = auc)) + scale_x_continuous(breaks =seq(0,1500,by = 100))\n",
    "\n",
    "# Performance of Base Model\n",
    "prob<-predict(xgb,as.matrix(x_train))\n",
    "train_out <- data.frame(actual=y_train,prob=prob)\n",
    "a = eval_func(train_out$actual, train_out$prob)\n",
    "auc_train = auc_func(train_out)\n",
    "gini_train = unlist(a[1])\n",
    "ks_train = unlist(a[2])\n",
    " \n",
    "prob<-predict(xgb,as.matrix(x_test))\n",
    "test_out <- data.frame(actual=y_test,prob=prob)\n",
    "a = eval_func(test_out$actual, test_out$prob)\n",
    "auc_test = auc_func(test_out)\n",
    "gini_test = unlist(a[1])\n",
    "ks_test = unlist(a[2])\n",
    " \n",
    "prob<-predict(xgb,as.matrix(x_oot))\n",
    "oot_out <- data.frame(actual=y_oot,prob=prob)\n",
    "a = eval_func(oot_out$actual, oot_out$prob)\n",
    "auc_oot = auc_func(oot_out)\n",
    "gini_oot = unlist(a[1])\n",
    "ks_oot = unlist(a[2])\n",
    " \n",
    "# Base Model Performance\n",
    "cat(auc_train, gini_train, ks_train, auc_test, gini_test, ks_test, auc_oot, gini_oot, ks_oot, (ks_train - ks_test)/ks_train, (ks_test - ks_oot)/ks_test)\n",
    "print(\"Model has trained!\")\n",
    " \n",
    "# Features importance of Base Model\n",
    "var_imp_all_vars <- xgb.importance(xgb$feature_names, model = xgb)\n",
    "Feature_imp <- as.data.frame(var_imp_all_vars)\n",
    "colnames(Feature_imp)[1] <- \"Attribute\"\n",
    "Feature_imp <- Feature_imp %>% left_join(dictionary, by = \"Attribute\")\n",
    "write.csv(Feature_imp, Feat_imp_file_name)\n",
    " \n",
    " \n",
    "#######################################################################################\n",
    "model_results <- matrix(c(auc_train, auc_test, auc_oot, gini_train, gini_test, gini_oot, ks_train, ks_test, ks_oot, (ks_train-ks_train)/ks_train , (ks_train-ks_test)/ks_train, (ks_train-ks_oot)/ks_train), nrow = 3, ncol = 4)\n",
    " \n",
    "model_results <- data.frame(model_results)\n",
    "colnames(model_results) <- c(\"AUC\", \"Gini\", \"KS\", \"KS Drop\")\n",
    "rownames(model_results) <- c(\"Train\", \"Test\", \"OOT\")\n",
    " \n",
    "#class_description = matric(c())\n",
    " \n",
    "train_ks_table = ksTable(train_out$actual, train_out$prob)\n",
    "test_ks_table = ksTable(test_out$actual, test_out$prob)\n",
    "oot_ks_table = ksTable(oot_out$actual, oot_out$prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a6536",
   "metadata": {},
   "source": [
    "## 13. KS Table & Feature Importance File Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7557be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the Excel format style\n",
    "wb <- createWorkbook()\n",
    " \n",
    "headerStyle <- createStyle(textDecoration = \"bold\", border = \"TopBottomLeftRight\", halign = \"center\", valign=\"center\", fgFill = \"#B4C6E7\")\n",
    "borderStyle <- createStyle(border = \"TopBottomLeftRight\")\n",
    "BoldStyle <- createStyle(textDecoration = \"bold\", halign = \"center\", valign=\"center\")\n",
    "NumStyle <- createStyle(border = \"TopBottomLeftRight\", halign = \"center\", valign=\"center\")\n",
    "PercentageStyle <- createStyle(border = \"TopBottomLeftRight\", halign = \"center\", valign=\"center\", numFmt=\"PERCENTAGE\")\n",
    " \n",
    "#########################################################################################\n",
    "### Adding the KS-Table workbook\n",
    "addWorksheet(wb,\"KS-Table\")\n",
    " \n",
    " \n",
    "writeData(wb,\"KS-Table\",model_results,startRow = 2,startCol = 2,colNames = TRUE,headerStyle = headerStyle, rowNames = TRUE)\n",
    "addStyle(wb,\"KS-Table\",headerStyle, rows=2,cols=2:6,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",headerStyle,rows=3:5,cols=2,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",NumStyle,rows=3:5,cols=3:6,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",PercentageStyle,rows=3:5,cols=6,gridExpand = TRUE)\n",
    "writeData(wb,\"KS-Table\",x=\"\",startRow = 6,startCol = 2)\n",
    " \n",
    "writeData(wb,\"KS-Table\",x=\"TRAIN\",startRow = 9,startCol = 2)\n",
    "addStyle(wb,\"KS-Table\",BoldStyle,rows=9,cols=2,gridExpand = TRUE)\n",
    "writeData(wb,\"KS-Table\",train_ks_table,startRow = 11,startCol = 2,colNames = TRUE,headerStyle = headerStyle, rowNames = FALSE)\n",
    "addStyle(wb,\"KS-Table\",NumStyle,rows=12:21,cols=2:14,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",PercentageStyle,rows=12:21,cols=7:8,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",PercentageStyle,rows=12:21,cols=11:12,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",PercentageStyle,rows=12:21,cols=14,gridExpand = TRUE)\n",
    " \n",
    " \n",
    " \n",
    "writeData(wb,\"KS-Table\",x=\"\",startRow = 22,startCol = 2)\n",
    " \n",
    "writeData(wb,\"KS-Table\",x=\"TEST\",startRow = 25,startCol = 2,headerStyle = headerStyle)\n",
    "addStyle(wb,\"KS-Table\",BoldStyle,rows=25,cols=2,gridExpand = TRUE)\n",
    "writeData(wb,\"KS-Table\",test_ks_table,startRow = 27,startCol = 2,colNames = TRUE,headerStyle = headerStyle, rowNames = FALSE)\n",
    "addStyle(wb,\"KS-Table\",NumStyle,rows=28:37,cols=2:14,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",PercentageStyle,rows=28:37,cols=7:8,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",PercentageStyle,rows=28:37,cols=11:12,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",PercentageStyle,rows=28:37,cols=14,gridExpand = TRUE)\n",
    " \n",
    "writeData(wb,\"KS-Table\",x=\"\",startRow = 38,startCol = 2)\n",
    " \n",
    "writeData(wb,\"KS-Table\",x=\"OOT\",startRow = 41,startCol = 2,headerStyle = headerStyle)\n",
    "addStyle(wb,\"KS-Table\",BoldStyle,rows=41,cols=2,gridExpand = TRUE)\n",
    "writeData(wb,\"KS-Table\",oot_ks_table,startRow = 43,startCol = 2,colNames = TRUE,headerStyle = headerStyle, rowNames = FALSE)\n",
    "addStyle(wb,\"KS-Table\",NumStyle,rows=44:53,cols=2:14,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",PercentageStyle,rows=44:53, cols=7:8,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",PercentageStyle,rows=44:53, cols=11:12,gridExpand = TRUE)\n",
    "addStyle(wb,\"KS-Table\",PercentageStyle,rows=44:53, cols=14,gridExpand = TRUE)\n",
    " \n",
    " \n",
    "######### Adding Feature Importance\n",
    "addWorksheet(wb,\"Feature_imp\")\n",
    "writeData(wb,\"Feature_imp\",Feature_imp,startRow = 1,startCol = 1,colNames = TRUE,headerStyle = headerStyle, rowNames = FALSE)\n",
    "addStyle(wb,\"Feature_imp\",headerStyle, rows=1,cols=1:5,gridExpand = TRUE)\n",
    "addStyle(wb,\"Feature_imp\", borderStyle,rows=2:nrow(Feature_imp)+1,cols=1:5,gridExpand = TRUE)\n",
    "addStyle(wb,\"Feature_imp\",NumStyle,rows=2:nrow(Feature_imp)+1,cols=2:4,gridExpand = TRUE)\n",
    " \n",
    " \n",
    " \n",
    "saveWorkbook(wb,paste0(model_saving_dir, \"model_report_\", model_version, \".xlsx\"),overwrite = TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640706d",
   "metadata": {},
   "source": [
    "## 14. Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e42c6",
   "metadata": {},
   "source": [
    "### 14.1 Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train <- train_data[, c(model_var, target, \"weight\")]\n",
    "#%>% sample_n(size = 140700)\n",
    " \n",
    "x_train = x_train %>%\n",
    "  mutate_at(model_var, ~ ifelse(is.na(.) | . <0, -99, .))\n",
    " \n",
    "# Default Binning\n",
    "initParallel(seq)\n",
    "bins <- newBinning(\n",
    "  data = x_train\n",
    "  , target = target\n",
    "  , weights = \"weight\"\n",
    "  , varsToInclude = model_var\n",
    ")\n",
    " \n",
    "saveRDS(bins, bin_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb22f20",
   "metadata": {},
   "source": [
    "### 14.2 Wellbinned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644520ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wellBinned <- names(bins$rejectCodes[bins$rejectCodes == 0])\n",
    "iv <- lapply(bins$bins, function(x)\n",
    "{\n",
    "  sum(x$IV)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9603a44",
   "metadata": {},
   "source": [
    "### 14.3 Features with IV > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52390235",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get variable list with IV > 0.1\n",
    "iv <- unlist(iv)\n",
    "iv <- data.frame(Attribute = names(iv), IV = iv) %>% arrange(desc(IV)) %>% filter( IV != Inf)\n",
    "iv <- left_join(iv, dictionary, by = \"Attribute\")\n",
    "iv_top_vars_df <- iv %>% filter (IV>0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68c4f3",
   "metadata": {},
   "source": [
    "### 14.4 Selecting Intersection Variables Based on Information Value (IV) and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5727dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_imp_vars <- as.vector(Feature_imp$Attribute)\n",
    "iv_top_vars <- as.vector(iv_top_vars_df$Attribute)\n",
    "model_vars1 <- union(intersect(wellBinned,iv_top_vars), intersect(wellBinned,Feature_imp_vars))\n",
    "\n",
    "# Joining description to the Features\n",
    "var_df <- data.frame(\"Attribute\" = model_vars1)\n",
    "var_df1 <- inner_join(var_df, iv, by = \"Attribute\") %>% arrange(desc(IV))\n",
    "vars_after_IV_FI = paste0(model_saving_dir, vars_after_IV_FI,\"_\", model_version, \".csv\")\n",
    " \n",
    "write.csv(var_df1, vars_after_IV_FI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761a6a60",
   "metadata": {},
   "source": [
    "## 15. Correlation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d31df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train <- train_data[, c(model_var, target, \"weight\")]\n",
    " \n",
    "x_train = x_train %>%\n",
    "  mutate_at(model_var, ~ ifelse(is.na(.) | . <0, -99, .))\n",
    " \n",
    "## Check correlation; Variables are passed in descending order by IV\n",
    "run_correlation_check <- function(data, cor_thr = 0.4){\n",
    "  cor_mat <- cor(data)\n",
    "  diag(cor_mat) <- 0\n",
    "  cat(\"\\n\", \"Max Correlation:\", max(cor_mat))\n",
    "  i <- 1\n",
    "  test <- 1\n",
    "  while (test > 0) {\n",
    "    idx <- which(abs(cor_mat[i,]) >= cor_thr)\n",
    "    if (length(idx) == 0){\n",
    "      i <- i + 1\n",
    "    }else{\n",
    "      cor_mat <- cor_mat[-idx, -idx]\n",
    "    }\n",
    "    test <- sum(cor_mat >= cor_thr)\n",
    "  }\n",
    "  cat(\"\\n\", \"Updated Max Correlation:\", max(cor_mat), \"\\n\")\n",
    "  return(rownames(cor_mat))\n",
    "}\n",
    " \n",
    "## Select the lowest correlation threshold where we get sufficient number of variables\n",
    "low_corr_cols_03 <- run_correlation_check(x_train[, final_model_vars], 0.3)\n",
    "low_corr_cols_04 <- run_correlation_check(x_train[, final_model_vars], 0.4)\n",
    "low_corr_cols_05 <- run_correlation_check(x_train[, final_model_vars], 0.5)\n",
    "low_corr_cols_06 <- run_correlation_check(x_train[, final_model_vars], 0.6)\n",
    " \n",
    "saveRDS(low_corr_cols_03, paste0(model_saving_dir, \"low_corr_cols_with_threshold_03.rds\"))\n",
    "saveRDS(low_corr_cols_04, paste0(model_saving_dir, \"low_corr_cols_with_threshold_04.rds\"))\n",
    "saveRDS(low_corr_cols_05, paste0(model_saving_dir, \"low_corr_cols_with_threshold_05.rds\"))\n",
    "saveRDS(low_corr_cols_06, paste0(model_saving_dir, \"low_corr_cols_with_threshold_06.rds\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
