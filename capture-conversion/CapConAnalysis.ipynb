{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cc1ff1",
   "metadata": {},
   "source": [
    "Initializing pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276deb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('abc').getOrCreate()\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404bbe28",
   "metadata": {},
   "source": [
    "Defining function for calculating capture rate and conversion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f108afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cap_conv_rate(df,target_cols,long_target)\n",
    "    list1=target_cols\n",
    "    list3 = []\n",
    "    list4 = []\n",
    "    list5 = []\n",
    "    final_target = long_target\n",
    "\n",
    "    for flag in list1\n",
    "        conversion_rate = (df.filter((F.col(flag)==1) & (F.col(final_target)  ==1)).count())/(df.filter(F.col(flag)==1).count())\n",
    "        list3.append(conversion_rate)\n",
    "        bad_count = (df.filter(F.col(flag)==1).count())\n",
    "        total_count = (df.count())\n",
    "        list4.append(bad_count)\n",
    "    for flag in list1\n",
    "        capture_rate = (df.filter((F.col(flag)==1) & (F.col(final_target)==1)).count()) / (df.filter(F.col(final_target)==1).count())\n",
    "        list5.append(capture_rate)\n",
    "    data = list(zip(list1,list4,[total_count]*len(list1),list5,list3))\n",
    "    deptSchema = StructType([\n",
    "        StructField('flag',StringType(),True),\n",
    "        StructField('bad_count',IntegerType(),True),\n",
    "        StructField('total_count',IntegerType(),True),\n",
    "        StructField('Capture_rate',DoubleType(),True),\n",
    "        StructField('Conversion_rate',DoubleType(),True)])\n",
    "    df_final = spark.createDataFrame(data, schema=deptSchema)\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c024b4",
   "metadata": {},
   "source": [
    "Creating target columns: assuming the data has dpd data for all the dpd months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbfa34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpd_months = [6,9,12,15,18,24]\n",
    "\n",
    "exp2 = ['*']\\\n",
    "+[f\"case when max_dpd{i}mob >= 30 then 1 else 0 end as targer_{i}mob_30_flag\" for i in dpd_months]\\\n",
    "+[f\"case when max_dpd{i}mob >= 60 then 1 else 0 end as targer_{i}mob_60_flag\" for i in dpd_months]\\\n",
    "+[f\"case when max_dpd{i}mob >= 90 then 1 else 0 end as targer_{i}mob_90_flag\" for i in dpd_months]\\\n",
    "+[f\"case when max_dpd{i}mob >= 120 then 1 else 0 end as targer_{i}mob_120_flag\" for i in dpd_months]\\\n",
    "+[f\"case when max_dpd{i}mob >= 150 then 1 else 0 end as targer_{i}mob_150_flag\" for i in dpd_months]\\\n",
    "+[f\"case when max_dpd{i}mob >= 180 then 1 else 0 end as targer_{i}mob_180_flag\" for i in dpd_months]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21052286",
   "metadata": {},
   "source": [
    "Running Cap Con analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400fe95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"select * from data_table\")\n",
    "\n",
    "df1 = df.selectExpr(exp2)\n",
    "long_target = \"target_24mob_180_flag\"\n",
    "target_cols = [i for i in df1.columns if 'target' in 1]\n",
    "df_final = get_cap_conv_rate(df1,target_cols,long_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
